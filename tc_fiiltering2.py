# -*- coding: utf-8 -*-
"""TC-Fiiltering2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cr7al1x3V4YM5hLrXfh4Ar53GNfmoJLJ
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content
!git clone https://github.com/ultralytics/yolov5
# %cd yolov5
!pip install -r requirements.txt

from google.colab import drive
drive.mount('/content/drive')

import sys
sys.path.append('/content/yolov5')
sys.path.append('/content/drive/MyDrive/Colab Notebooks/CVIP_LAB/UAV/Track 1')

# 구글 드라이브의 zip 파일을 직접 /content/data 폴더에 조용히(-q) 압축 해제
!unzip -q "/content/drive/MyDrive/Colab Notebooks/CVIP_LAB/UAV/Track 1/tar_file/train.zip" -d /content/data
!unzip -q "/content/drive/MyDrive/Colab Notebooks/CVIP_LAB/UAV/Track 1/tar_file/track1_test.zip" -d /content/data

!rm -rf /content/data/__MACOSX

!ls /content/yolov5/Datasets/train | head

import json
with open("/content/data/train/01_1751_0250-1750/IR_label.json") as f:
    data = json.load(f)
print(type(data))
print(data.keys() if isinstance(data, dict) else data[:1])

data['gt_rect'][:5]

import os
drive_path = '/content/drive/MyDrive/Colab Notebooks/CVIP_LAB/UAV/Track 1'
track1_test_path = '/content/data/track1_test'

print(f"Checking directory : {track1_test_path}")

if os.path.exists(track1_test_path):
    print("Directory Exists. Listing Contents.")
    contents = os.listdir(track1_test_path)
    if contents:
        for content in contents[:10]:
            print(f"- {content}")
        if len(contents) > 10:
            print(f"... and {len(contents) - 10} more items")
        else:
            print("Directory is empty")
else:
    print("Directory does not exist.")

# Link to Yolov5
!ln -s /content/data /content/yolov5/Datasets
!ls /content/yolov5/Datasets/train | head

file_path = '/content/yolov5/Datasets/train/01_2192_0001-1500/IR_label.json'
with open(file_path, 'r') as f:
    data = json.load(f)
print(f"포함된 Key 목록 : {list(data.keys())}")
print("-" * 20)

for key in data.keys():
    length = len(data[key])
    print(f"Key : {key:10} | 데이터 개수 : {length}")
print("-" * 20)
print("첫 번째 프레임 (Index 0)의 상태 : ")
print(f"  - 존재 여부 (Exist) : {data['exist'][0]}")
print(f"  - 좌표 (gt_rect) : {data['gt_rect'][0]}")
print(f"  - 가림 여부 (OC) : {data['OC'][0]}")

from __future__ import absolute_import
import numpy as np
import cv2
from tqdm import tqdm
import json
import glob
import os

from detection_siamfc import TrackerSiamFC

def iou(bbox1, bbox2):
    bbox1 = [float(x) for x in bbox1]
    bbox2 = [float(x) for x in bbox2]

    (x0_1, y0_1, w1_1, h1_1) = bbox1
    (x0_2, y0_2, w1_2, h1_2) = bbox2
    x1_1 = x0_1 + w1_1
    x1_2 = x0_2 + w1_2
    y1_1 = y0_1 + h1_1
    y1_2 = y0_2 + h1_2

    overlap_x0 = max(x0_1, x0_2)
    overlap_y0 = max(y0_1, y0_2)
    overlap_x1 = min(x1_1, x1_2)
    overlap_y1 = min(y1_1, y1_2)

    if overlap_x1 - overlap_x0 <= 0 or overlap_y1 - overlap_y0 <=0:
        return 0

    size_1 = (x1_1 - x0_1) * (y1_1 - y0_1)
    size_2 = (x1_2 - x0_2) * (y1_2 - y0_2)

    size_intersection = (overlap_x1 - overlap_x0) * (overlap_y1 - overlap_y0)
    size_union = size_1 + size_2 - size_intersection

    return size_intersection / size_union

def not_exist(pred):
    return (len(pred) == 1 and pred[0] == 0) or (len(pred) == 0)

def eval(out_res, label_res):
    measure_per_frame = []
    penalty_measure = []
    for _pred, _gt, _exist in zip(out_res, label_res['gt_rect'], label_res['exist']):
        # Target 존재 x : _exist==False | Target 존재 O : _exist == True
        measure_per_frame.append(not_exist(_pred) if not _exist else iou(_pred, _gt) if len(_pred) > 1 else 0)
        if _exist:
            if (len(_pred) > 1 and iou(_pred, _gt) > 1e-5):
                penalty_measure.append(0)
            else:
                penalty_measure.append(1)
    if len(measure_per_frame) == 0:
        measure_per_frame_mean = 0
    else:
        measure_per_frame_mean = np.mean(measure_per_frame)

    if len(penalty_measure) == 0:
        penalty_measure_mean = 0
    else:
        penalty_measure_mean = np.mean(penalty_measure)

    return measure_per_frame_mean - 0.2 * (penalty_measure_mean ** 0.3)

# import os
# import cv2
# import json
# import glob
# import torch
# import numpy as np
# def main(mode='IR', visualization=False):
#     # Lucas-Kanade Optical Flow Parameter settings.
#     # == Lucas-Kanade operate flow ==
#     # p0 (prev frame)  -> calcOpticalFlowPyrLK -> p1(current frame position)
#     # p0 : feature coordinate on prev_frame  |   p1 : position of the feature at current frame
#     # and estimae camera motion matrix by using ` M = estimateAffinePartial2D(good_old, good_new)`
#     lk_params = dict(
#         winSize=(15, 15),
#         maxLevel=2,
#         criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)
#     )
#     global drive_path
#     device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
#     print(f"현재 사용 장치 : {device}")

#     net_path = os.path.join(drive_path, "Baseline_code", 'model.pth')
#     tracker = TrackerSiamFC(net_path=net_path)
#     yolo_model = tracker.initialize_yolo()
#     yolo_model.to(device)
#     tracker.net.to(device)

#     video_paths = glob.glob('/content/data/track1_test/*')
#     output_dir = os.path.join('results', tracker.name)
#     os.makedirs(output_dir, exist_ok=True)

#     overall_success = []

#     for video_id, video_path in enumerate(video_paths, start=1):
#         print(f"\n===== {video_id}/{len(video_paths)} =====")
#         gmc_initialized = False
#         track_active = False
#         prev_gray = None
#         p0 = None
#         video_name = os.path.basename(video_path)
#         frame_files = sorted([
#             f for f in os.listdir(video_path)
#             if f.endswith(('.jpg', '.png', '.jpeg'))
#         ])
#         res_file = os.path.join(video_path, 'IR_label.json')
#         with open(res_file, 'r') as f:
#             label_res = json.load(f)

#         if 'exist' not in label_res:
#             label_res['exist'] = [1] * len(label_res['gt_rect'])

#         gt_rects = label_res['gt_rect']
#         exist_flags = label_res['exist']
#         video_ious = []

#         # Calculate num_frames to prevent IndexError
#         if len(gt_rects) > 0:
#             num_frames = min(len(frame_files), len(gt_rects))
#         else:
#             num_frames = len(frame_files)

#         for frame_id in range(num_frames):
#             frame_file = frame_files[frame_id]
#             frame_path = os.path.join(video_path, frame_file)
#             frame = cv2.imread(frame_path)
#             curr_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
#             im_vis = frame.copy()

#             if not track_active:
#                 pred_bbox, im_vis = tracker.init(frame, yolo_model)
#                 if len(pred_bbox) > 1:
#                     track_active = True
#                     gmc_initialized = False
#                 else:
#                     pred_bbox = [0]
#             else:

#                 pred_bbox = tracker.update(frame)

#                 if len(pred_bbox) == 1:
#                     track_active = False
#                     gmc_initialized = False
#                     pred_bbox = [0]
#             if track_active and not gmc_initialized:

#                 prev_gray = curr_gray.copy()
#                 p0 = cv2.goodFeaturesToTrack(prev_gray, 80, 0.01, 7, blockSize=7)
#                 gmc_initialized = True

#             elif track_active and gmc_initialized:

#                 if p0 is not None and len(p0) > 15:

#                     p1, st, err = cv2.calcOpticalFlowPyrLK(
#                         prev_gray, curr_gray, p0, None, **lk_params)
#                     good_new = p1[st == 1]
#                     good_old = p0[st == 1]
#                     if len(good_old) > 15:
#                         M, _ = cv2.estimateAffinePartial2D(
#                             good_old, good_new,
#                             method=cv2.RANSAC,
#                             ransacReprojThreshold=3)

#                         if M is not None:

#                             h_img, w_img = curr_gray.shape
#                             warped_prev = cv2.warpAffine(prev_gray, M, (w_img, h_img))
#                             residual = cv2.absdiff(warped_prev, curr_gray)

#                             x, y, w, h = map(int, pred_bbox)
#                             x = max(0, x)
#                             y = max(0, y)
#                             w = min(w, w_img - x)
#                             h = min(h, h_img - y)

#                             inside = residual[y:y+h, x:x+w]
#                             inside_score = np.mean(inside)

#                             outside_mask = np.ones_like(residual, dtype=np.uint8)
#                             outside_mask[y:y+h, x:x+w] = 0
#                             outside_score = np.mean(residual[outside_mask == 1])

#                             ratio = inside_score / (outside_score + 1e-6)

#                             if ratio < 1.1:
#                                 track_active = False
#                                 gmc_initialized = False
#                                 pred_bbox = [0]

#                     if len(good_new) > 0:
#                         p0 = good_new.reshape(-1, 1, 2)

#                 if p0 is None or len(p0) < 20:
#                     p0 = cv2.goodFeaturesToTrack(prev_gray, 80, 0.01, 7, blockSize=7)

#             prev_gray = curr_gray.copy()
#             # Ensure frame_id is within bounds of gt_rects and exist_flags
#             if frame_id < len(gt_rects) and exist_flags[frame_id] == 1:

#                 if len(pred_bbox) > 1:
#                     iou_score = iou(pred_bbox, gt_rects[frame_id])
#                 else:
#                     iou_score = 0.0

#                 video_ious.append(iou_score)

#             # Visualization
#             if visualization and len(pred_bbox) > 1:
#                 x, y, w, h = map(int, pred_bbox)
#                 cv2.rectangle(im_vis, (x, y), (x+w, y+h), (0,0,255), 2)
#                 cv2.imshow(video_name, im_vis)
#                 cv2.waitKey(1)
#         if len(video_ious) > 0:
#             video_success = np.mean(video_ious)
#             overall_success.append(video_success)
#             print(f"{video_name} Success: {video_success:.4f}")
#     if len(overall_success) > 0:
#         final_score = np.mean(overall_success)
#         print("\n===============================")
#         print(f"Overall Success: {final_score:.4f}")
#         print("===============================")
# if __name__ == '__main__':
#     main(mode='IR', visualization=False)

import torch
def main(mode='IR', visualization=False):
    # Lucas-Kanade Optical Flow Parameter settings.
    # == Lucas-Kanade operate flow ==
    # p0 (prev frame)  -> calcOpticalFlowPyrLK -> p1(current frame position)
    # p0 : feature coordinate on prev_frame  |   p1 : position of the feature at current frame
    # and estimae camera motion matrix by using ` M = estimateAffinePartial2D(good_old, good_new)`
    global drive_path

    lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))
    assert mode in ['IR', 'RGB'], 'Only Suport IR or RGB to evaluate'

    device = torch.device('cuda:0' if torch.cuda.is_available() else "cpu")
    print(f"현재 사용 장치 : {device}")

    net_path = os.path.join(drive_path, "Baseline_code", "model.pth")
    tracker = TrackerSiamFC(net_path=net_path, device=device)
    yolo_model = tracker.initialize_yolo()
    yolo_model.to(device)
    tracker.net.to(device)

    save_root = os.path.join(drive_path, "results", tracker.name)
    os.makedirs(save_root, exist_ok=True)
    result_file = os.path.join(save_root, "per_video_success.txt")

    if os.path.exists(result_file):
        os.remove(result_file)

    #video_paths = glob.glob(os.path.join(os.path.join('/content/data/track1_test'), "*"))
    video_paths = glob.glob('/content/data/track1_test/*')

    #output_dir = os.path.join('results', tracker.name)
    output_dir = os.path.join(save_root, "per_video_outputs")
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    overall_performance = [] # overall_success

    for video_id, video_path in enumerate(video_paths, start=1):
        print(f"\n==== {video_id} / {len(video_paths)} =====")
        gmc_initialized = False
        track_active = False
        prev_gray = None
        p0 = None

        video_name = os.path.basename(video_path)
        #video_file = os.path.join(video_path, "%s.mp4"%mode)
        frame_files = sorted(
            [f for f in os.listdir(video_path) if f.endswith(('.jpg', '.jpeg', '.png', '.bmp'))])

        # GT Load
        res_file = os.path.join(video_path, "IR_label.json")
        with open(res_file, 'r') as f:
            label_res = json.load(f)
        if 'exist' not in label_res:
            label_res['exist'] = [1] * len(label_res['gt_rect'])
        gt_rects = label_res['gt_rect']
        exist_flags = label_res['exist']

        video_ious = []

        output_file = os.path.join(output_dir, f"{video_name}.txt")

        # ============= 이 부분 주석 해제 : 재 계산 안함 ==========
        # if os.path.exists(output_file):
        #     try:
        #         with open(output_file, 'r') as file:
        #             data = json.load(file)
        #             out_res = data['res']
        #             # content=  file.read()
        #             # data = json.loads(content)
        #             # out_res = data['res']
        #     except Exception as e:
        #         print(f"{video_name}")
        #         out_res = []
        if False:
            pass
        else:
        # ============= 이 부분 주석 해제 : 재 계산 안함 ==========
            #print_frame_id = 0
            out_res = []
            pred_bbox=[0]

            #for frame_id, frame_file in enumerate(frame_files):


            #num_frames = min(len(frame_files), len(gt_rects))

            if len(gt_rects) > 1:
                num_frames = min(len(frame_files), len(gt_rects))
            else:
                num_frames = len(frame_files)

            for frame_id in range(num_frames):
                frame_file = frame_files[frame_id]
                frame_path = os.path.join(video_path, frame_file)
                frame = cv2.imread(frame_path)

                curr_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                im_vis = frame.copy() # for Visualization

                if not track_active: # 현재 추적중인 대상이 없음 : YOLO 필요함
                    pred_bbox, im_vis = tracker.init(frame, yolo_model) # YOLO를 통해서 Detect하고, YOLO가 못찾으면 [0] 반환함. YOLO가 찾으면 SiamFC에게 넘겨줄 준비 함. -> tracker.update
                    if len(pred_bbox) > 1:
                        track_active = True
                        gmc_initialized=False
                        # As Tracking is just started, optical_flow standard (prev_gray, p0) No exists.
                        # GMC : Estimating Camera Motions between "Prev_frame" & "Current Frame"
                        # But in this case, "Motion Standard"(As tracking was dead just before frame. So prev_gray is not the standard of tracking.) does not exists.
                    else:
                        pred_bbox = [0]

                else: # 현재 추적중인 대상이 있음 : SiamFC 수행
                    pred_bbox = tracker.update(frame) # Update된 BB 받아옴
                    if len(pred_bbox) == 1:
                        track_active=False
                        gmc_initialized=False
                        pred_bbox = [0]

                if track_active and not gmc_initialized:
                    prev_gray = curr_gray.copy()
                    p0 = cv2.goodFeaturesToTrack(prev_gray, 80, 0.01, 7, blockSize=7)
                    # p0 : Selected corner features at the prev_frame.
                    # Shape of p0 : (N, 1, 2)
                    gmc_initialized=True

                elif track_active and gmc_initialized:
                    if p0 is not None and len(p0) > 15:
                        p1, st, err = cv2.calcOpticalFlowPyrLK(
                            prev_gray, curr_gray, p0, None, **lk_params
                        )
                        good_new = p1[st==1]
                        good_old = p0[st==1]

                        if len(good_old) > 15:
                            M, _ = cv2.estimateAffinePartial2D(good_old, good_new, method=cv2.RANSAC, ransacReprojThreshold=3)
                            if M is not None:
                                h_img, w_img = curr_gray.shape
                                warped_prev = cv2.warpAffine(prev_gray, M, (w_img, h_img))
                                residual = cv2.absdiff(warped_prev, curr_gray)

                                x, y, w, h = map(int, pred_bbox)
                                x = max(0, x)
                                y = max(0, y)
                                w = min(w, w_img - x)
                                h = min(h, h_img - y)

                                inside=residual[y:y+h, x:x+w]
                                inside_score = np.mean(inside)

                                outside_mask = np.ones_like(residual, dtype=np.uint8)
                                outside_mask[y:y+h, x:x+w] = 0

                                outside_score = np.mean(residual[outside_mask == 1])

                                ratio = inside_score/(outside_score + 1e-6)

                                if ratio < 1.1:
                                    track_active = False
                                    gmc_initialized = False
                                    pred_bbox = [0]

                        if len(good_new) > 0:
                            p0 = good_new.reshape(-1, 1, 2)
                    if p0 is None or len(p0) < 20:
                        p0 = cv2.goodFeaturesToTrack(prev_gray, 80, 0.01, 7, blockSize=7)
                prev_gray = curr_gray.copy()

                # if exist_flags[frame_id] == 1:
                #     if len(pred_bbox) > 1:
                #         iou_score = iou(pred_bbox, gt_rects[frame_id])
                #     else:
                #         iou_score = 0.0
                #     video_ious.append(iou_score)

                if frame_id < len(gt_rects) and exist_flags[frame_id] == 1:
                    if len(pred_bbox) > 1:
                        iou_score = iou(pred_bbox, gt_rects[frame_id])
                    else:
                        iou_score = 0.0
                    video_ious.append(iou_score)

                if len(pred_bbox) > 1:
                    pred_bbox = [float(x) for x in pred_bbox]

                out_res.append(pred_bbox)

                if visualization and len(pred_bbox) > 1:
                    x, y, w, h = map(int, pred_bbox)
                    cv2.rectangle(im_vis, (x, y), (x+w, y+h), (0, 0, 255), 2)
                    cv2.imshow(video_name, im_vis)
                    cv2.waitKey(1)


            print("len(frame_files):", len(frame_files))
            print("len(gt_rects):", len(gt_rects))
            print("num_frames:", num_frames)


            with open(output_file, "w") as f:
                json.dump({"res": out_res}, f)


            if len(video_ious) > 0:
                video_success = np.mean(video_ious)
                overall_performance.append(video_success)
                print(f"{video_name} Success : {video_success:.4f}")

                # ===== 결과 저장 =====
                #save_root = os.path.join("results", "Yolo_SiamFC")
                #os.makedirs(save_root, exist_ok=True)

                #result_file = os.path.join(save_root, "per_video_success.txt")

                with open(result_file, "a") as f:
                    f.write(f"{video_name} {video_success:.4f}\n")

                # ======================
    if len(overall_performance) > 0:
        final_score = np.mean(overall_performance)
        print("\n=========================")
        print(f"Overall Success : {final_score:.4f}")
        print("=========================")

        overall_file = os.path.join(save_root, "overall_success.txt")
        with open(overall_file, "w") as f:
            f.write(f"Overall Success : {final_score:.4f}\n")
if __name__ == '__main__':
    main(mode='IR', visualization=False)

import os

source_dir = os.path.join('results', 'Yolo_SiamFC')

print("Source path:", source_dir)
print("Exists:", os.path.exists(source_dir))
print("Files:", os.listdir(source_dir))

import os
import shutil
import datetime

source_dir = os.path.join('results', 'Yolo_SiamFC')

timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
backup_dir = os.path.join(drive_path, f'Yolo_SiamFC_{timestamp}')

print(f"Backing up to: {backup_dir}")

shutil.copytree(source_dir, backup_dir)

print("Backup finished successfully.")

import cv2
import json
import os
import glob

# 1. 설정
#video_name = "1_1" # (혹은 37000... 등 실제 폴더명)
#video_name = "20190925_101846_1_4"
video_name = "03_2499_0962-2461"
drive_path = "/content/drive/MyDrive/Colab Notebooks/CVIP_LAB/UAV/Track 1"

image_folder = f"/content/data/track1_test/{video_name}"
#result_path = f"{drive_path}/results_backup/Yolo_SiamFC/{video_name}.txt"
result_path = f"{drive_path}/results/Yolo_SiamFC/per_video_outputs/{video_name}.txt"
output_video_path = f"{drive_path}/vis_result_{video_name}.mp4"

image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff')

if not os.path.exists(result_path):
    print(f"There is no result file: {result_path}")
else:
    with open(result_path, 'r') as f:
        data = json.load(f)
        predictions = data['res'] # [[x,y,w,h], ...]

    image_files = sorted([os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.lower().endswith(image_extensions)])

    if len(image_files) == 0:
        print(f"There is no single image. Check it out at : {image_folder}")
    else:
        print(f"총 {len(image_files)}장의 이미지를 찾았습니다.")

        # 첫 번째 이미지를 읽어서 영상 크기 결정
        first_frame = cv2.imread(image_files[0])
        height, width, layers = first_frame.shape

        # 비디오 저장 설정 (FPS는 30으로 설정)
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_video_path, fourcc, 30, (width, height))

        # 4. 한 장씩 읽으면서 박스 그리고 영상으로 저장
        for i, img_path in enumerate(image_files):
            frame = cv2.imread(img_path)

            if frame is None:
                continue

            # 예측 좌표가 있으면 그리기
            if i < len(predictions):
                bbox = predictions[i]
                if len(bbox) == 4: # [x, y, w, h] 형태일 때만
                    x, y, w, h = map(int, bbox)
                    # 파란색 박스 (BGR: Blue)
                    cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)
                    cv2.putText(frame, f"Frame: {i}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

            out.write(frame)

            if i % 100 == 0:
                print(f"... {i}번째 프레임 처리 중")

        out.release()
        print(f"\nSaved Visualization Video ")
        print(f"저장 경로: {output_video_path}")

valid_boxes = [b for b in predictions if len(b) == 4]
print("유효 박스 개수:", len(valid_boxes))

print("len:", len(predictions))
print("sample:", predictions[:10])
print("valid:", len([b for b in predictions if len(b)==4]))